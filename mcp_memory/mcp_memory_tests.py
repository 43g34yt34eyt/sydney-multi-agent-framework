#!/usr/bin/env python3
"""
MCP Memory Server Specific Tests

Focused testing suite for the MCP Memory Server component of the dual
memory architecture. Tests entity storage, relationship management,
and fast retrieval performance.

Usage:
    python mcp_memory_tests.py [test_name]
    
Tests:
    - entity_crud: Test CRUD operations on entities
    - relationship_management: Test relationship creation and queries  
    - fast_lookup: Test lookup performance and accuracy
    - memory_persistence: Test data persistence across restarts
    - concurrent_access: Test concurrent read/write operations
"""

import asyncio
import json
import time
import uuid
import subprocess
import tempfile
import os
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import sys

# Add project paths
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root.parent))

@dataclass
class MCPTestResult:
    """MCP-specific test result"""
    test_name: str
    status: str  # 'PASS', 'FAIL', 'SKIP'
    duration_ms: float
    memory_operations: int
    entities_processed: int
    relationships_processed: int
    evidence: Dict[str, Any]
    error_message: Optional[str] = None

class MCPMemoryTester:
    """
    Comprehensive tester for MCP Memory Server functionality
    
    Tests the memory server in isolation and as part of the dual
    memory architecture integration.
    """
    
    def __init__(self, memory_file_path: str = None):
        self.memory_file_path = memory_file_path or str(Path(__file__).parent / "test_data" / "test_memory.json")
        self.test_results: List[MCPTestResult] = []
        self.memory_server_process = None
        self.base_url = "http://localhost:3001"  # Typical MCP server port
        
        # Ensure test memory file exists
        Path(self.memory_file_path).parent.mkdir(parents=True, exist_ok=True)
        
        # Initialize empty memory file
        self._initialize_memory_file()
        
        print(f"üß† MCP Memory Server Tester initialized")
        print(f"   Memory file: {self.memory_file_path}")
    
    def _initialize_memory_file(self):
        """Initialize empty memory file"""
        initial_data = {
            "entities": [],
            "relations": []
        }
        
        with open(self.memory_file_path, 'w') as f:
            json.dump(initial_data, f, indent=2)
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """Run all MCP Memory Server tests"""
        
        print(f"\nüß™ RUNNING MCP MEMORY SERVER TESTS")
        print("=" * 60)
        
        try:
            # Start memory server if needed
            await self._ensure_memory_server_running()
            
            # Run test suite
            await self._test_entity_crud()
            await self._test_relationship_management()  
            await self._test_fast_lookup()
            await self._test_memory_persistence()
            await self._test_concurrent_access()
            await self._test_data_integrity()
            await self._test_query_performance()
            
            # Generate report
            return self._generate_test_report()
            
        finally:
            await self._cleanup()
    
    async def _ensure_memory_server_running(self):
        """Ensure MCP Memory Server is running for testing"""
        
        # For this test, we'll work directly with the memory file
        # In a full implementation, you would start the actual MCP server
        print("üìù Working with memory file directly (mock server)")
        print(f"   Memory file: {self.memory_file_path}")
    
    async def _test_entity_crud(self):
        """Test entity Create, Read, Update, Delete operations"""
        
        print(f"\nüîç Testing Entity CRUD Operations")
        print("-" * 40)
        
        start_time = time.time()
        
        try:
            # Load current memory state
            memory_data = self._load_memory_file()
            
            # Test CREATE operations
            test_entities = []
            for i in range(10):
                entity = {
                    "name": f"test_entity_{i}",
                    "entityType": "test_entity",
                    "observations": [
                        f"Test observation {i}",
                        f"Additional context for entity {i}",
                        f"Metadata: created during CRUD test"
                    ]
                }
                test_entities.append(entity)
                memory_data["entities"].append(entity)
            
            # Save updated memory
            self._save_memory_file(memory_data)
            
            # Test READ operations
            reloaded_data = self._load_memory_file()
            entities_found = [e for e in reloaded_data["entities"] if e["entityType"] == "test_entity"]
            
            # Test UPDATE operations
            for entity in entities_found[:5]:  # Update first 5
                entity["observations"].append("Updated during CRUD test")
                entity["last_updated"] = datetime.now(timezone.utc).isoformat()
            
            self._save_memory_file(reloaded_data)
            
            # Verify updates
            updated_data = self._load_memory_file()
            updated_entities = [e for e in updated_data["entities"] 
                              if e["entityType"] == "test_entity" and "last_updated" in e]
            
            # Test DELETE operations
            remaining_entities = [e for e in updated_data["entities"] 
                                if not (e["entityType"] == "test_entity" and e["name"].endswith("_0"))]
            updated_data["entities"] = remaining_entities
            
            self._save_memory_file(updated_data)
            
            # Verify deletion
            final_data = self._load_memory_file()
            final_entities = [e for e in final_data["entities"] if e["entityType"] == "test_entity"]
            
            duration = (time.time() - start_time) * 1000
            
            # Verify results
            create_success = len(entities_found) == 10
            read_success = len(entities_found) > 0
            update_success = len(updated_entities) == 5
            delete_success = len(final_entities) == 9  # Deleted 1
            
            all_operations_success = all([create_success, read_success, update_success, delete_success])
            
            result = MCPTestResult(
                test_name="entity_crud",
                status="PASS" if all_operations_success else "FAIL",
                duration_ms=duration,
                memory_operations=4,  # CREATE, READ, UPDATE, DELETE
                entities_processed=len(test_entities),
                relationships_processed=0,
                evidence={
                    "create_operations": len(test_entities),
                    "entities_created": len(entities_found),
                    "read_operations": 1,
                    "entities_read": len(entities_found),
                    "update_operations": 5,
                    "entities_updated": len(updated_entities),
                    "delete_operations": 1,
                    "entities_remaining": len(final_entities),
                    "create_success": create_success,
                    "read_success": read_success,
                    "update_success": update_success,
                    "delete_success": delete_success
                }
            )
            
            self.test_results.append(result)
            
            if all_operations_success:
                print(f"   ‚úÖ Entity CRUD: All operations successful")
            else:
                print(f"   ‚ùå Entity CRUD: Some operations failed")
                
        except Exception as e:
            duration = (time.time() - start_time) * 1000
            
            result = MCPTestResult(
                test_name="entity_crud",
                status="FAIL",
                duration_ms=duration,
                memory_operations=0,
                entities_processed=0,
                relationships_processed=0,
                evidence={},
                error_message=str(e)
            )
            
            self.test_results.append(result)
            print(f"   ‚ùå Entity CRUD failed: {e}")
    
    async def _test_relationship_management(self):
        """Test relationship creation and management"""
        
        print(f"\nüîó Testing Relationship Management")
        print("-" * 40)
        
        start_time = time.time()
        
        try:
            memory_data = self._load_memory_file()
            
            # Get existing test entities for relationships
            test_entities = [e for e in memory_data["entities"] if e["entityType"] == "test_entity"]
            
            if len(test_entities) < 2:
                # Create entities for relationship testing
                for i in range(5):
                    entity = {
                        "name": f"rel_entity_{i}",
                        "entityType": "relationship_test",
                        "observations": [f"Entity for relationship testing {i}"]
                    }
                    memory_data["entities"].append(entity)
                    test_entities.append(entity)
            
            # Create relationships between entities
            relationships_created = []
            relationship_types = ["related_to", "depends_on", "part_of", "similar_to"]
            
            for i in range(len(test_entities) - 1):
                from_entity = test_entities[i]
                to_entity = test_entities[i + 1]
                rel_type = relationship_types[i % len(relationship_types)]
                
                relationship = {
                    "from": from_entity["name"],
                    "to": to_entity["name"],
                    "relationship": rel_type,
                    "created_at": datetime.now(timezone.utc).isoformat(),
                    "strength": 0.8,
                    "metadata": {
                        "test_relationship": True,
                        "created_by": "relationship_test"
                    }
                }
                
                memory_data["relations"].append(relationship)
                relationships_created.append(relationship)
            
            # Save relationships
            self._save_memory_file(memory_data)
            
            # Test relationship queries
            reloaded_data = self._load_memory_file()
            
            # Query relationships by type
            related_to_relationships = [r for r in reloaded_data["relations"] 
                                      if r.get("relationship") == "related_to"]
            
            # Query relationships by entity
            entity_relationships = [r for r in reloaded_data["relations"]
                                  if r.get("from") == test_entities[0]["name"]]
            
            # Query all test relationships  
            test_relationships = [r for r in reloaded_data["relations"]
                                if r.get("metadata", {}).get("test_relationship")]
            
            duration = (time.time() - start_time) * 1000
            
            # Verify results
            creation_success = len(test_relationships) >= len(relationships_created)
            query_success = len(related_to_relationships) > 0 or len(entity_relationships) > 0
            
            result = MCPTestResult(
                test_name="relationship_management",
                status="PASS" if creation_success and query_success else "FAIL",
                duration_ms=duration,
                memory_operations=3,  # Create, Save, Query
                entities_processed=len(test_entities),
                relationships_processed=len(relationships_created),
                evidence={
                    "entities_available": len(test_entities),
                    "relationships_created": len(relationships_created),
                    "relationships_saved": len(test_relationships),
                    "relationship_types": len(set(r["relationship"] for r in relationships_created)),
                    "related_to_query_results": len(related_to_relationships),
                    "entity_query_results": len(entity_relationships),
                    "total_query_results": len(test_relationships),
                    "creation_success": creation_success,
                    "query_success": query_success
                }
            )
            
            self.test_results.append(result)
            
            if creation_success and query_success:
                print(f"   ‚úÖ Relationship Management: {len(relationships_created)} relationships created and queried")
            else:
                print(f"   ‚ùå Relationship Management: Failed to create or query relationships")
                
        except Exception as e:
            duration = (time.time() - start_time) * 1000
            
            result = MCPTestResult(
                test_name="relationship_management",
                status="FAIL",
                duration_ms=duration,
                memory_operations=0,
                entities_processed=0,
                relationships_processed=0,
                evidence={},
                error_message=str(e)
            )
            
            self.test_results.append(result)
            print(f"   ‚ùå Relationship Management failed: {e}")
    
    async def _test_fast_lookup(self):
        """Test fast entity lookup performance"""
        
        print(f"\n‚ö° Testing Fast Entity Lookup")
        print("-" * 40)
        
        start_time = time.time()
        
        try:
            memory_data = self._load_memory_file()
            
            # Create a large number of entities for lookup testing
            lookup_entities = []
            for i in range(1000):
                entity = {
                    "name": f"lookup_entity_{i:04d}",
                    "entityType": "lookup_test",
                    "observations": [f"Entity {i} for lookup performance testing"],
                    "searchable_field": f"value_{i}",
                    "category": f"category_{i % 10}"
                }
                lookup_entities.append(entity)
                memory_data["entities"].append(entity)
            
            self._save_memory_file(memory_data)
            
            # Test different types of lookups
            lookup_times = []
            
            # Test 1: Lookup by name
            for i in range(100):
                lookup_start = time.time()
                
                target_name = f"lookup_entity_{i:04d}"
                found_entity = None
                
                for entity in memory_data["entities"]:
                    if entity["name"] == target_name:
                        found_entity = entity
                        break
                
                lookup_time = (time.time() - lookup_start) * 1000
                lookup_times.append(lookup_time)
                
                await asyncio.sleep(0.001)  # Small delay to simulate realistic usage
            
            # Test 2: Lookup by type
            type_lookup_times = []
            for i in range(50):
                lookup_start = time.time()
                
                entities_of_type = [e for e in memory_data["entities"] 
                                  if e.get("entityType") == "lookup_test"]
                
                lookup_time = (time.time() - lookup_start) * 1000
                type_lookup_times.append(lookup_time)
                
                await asyncio.sleep(0.001)
            
            # Test 3: Lookup by category
            category_lookup_times = []
            for i in range(25):
                lookup_start = time.time()
                
                target_category = f"category_{i % 10}"
                category_entities = [e for e in memory_data["entities"]
                                   if e.get("category") == target_category]
                
                lookup_time = (time.time() - lookup_start) * 1000
                category_lookup_times.append(lookup_time)
                
                await asyncio.sleep(0.001)
            
            duration = (time.time() - start_time) * 1000
            
            # Calculate performance metrics
            avg_name_lookup = sum(lookup_times) / len(lookup_times)
            avg_type_lookup = sum(type_lookup_times) / len(type_lookup_times)
            avg_category_lookup = sum(category_lookup_times) / len(category_lookup_times)
            
            p95_name_lookup = sorted(lookup_times)[int(0.95 * len(lookup_times))]
            
            # Performance thresholds (in milliseconds)
            name_lookup_threshold = 10.0  # Should be very fast
            type_lookup_threshold = 50.0  # Can be slower as it scans
            category_lookup_threshold = 100.0  # Can be slowest
            
            performance_success = (
                avg_name_lookup < name_lookup_threshold and
                avg_type_lookup < type_lookup_threshold and 
                avg_category_lookup < category_lookup_threshold
            )
            
            result = MCPTestResult(
                test_name="fast_lookup",
                status="PASS" if performance_success else "FAIL",
                duration_ms=duration,
                memory_operations=3,  # Name, Type, Category lookups
                entities_processed=len(lookup_entities),
                relationships_processed=0,
                evidence={
                    "entities_created": len(lookup_entities),
                    "name_lookups": len(lookup_times),
                    "type_lookups": len(type_lookup_times),
                    "category_lookups": len(category_lookup_times),
                    "avg_name_lookup_ms": avg_name_lookup,
                    "avg_type_lookup_ms": avg_type_lookup,
                    "avg_category_lookup_ms": avg_category_lookup,
                    "p95_name_lookup_ms": p95_name_lookup,
                    "name_lookup_threshold_ms": name_lookup_threshold,
                    "type_lookup_threshold_ms": type_lookup_threshold,
                    "category_lookup_threshold_ms": category_lookup_threshold,
                    "performance_within_thresholds": performance_success,
                    "lookups_per_second": (len(lookup_times) + len(type_lookup_times) + len(category_lookup_times)) / (duration / 1000)
                }
            )
            
            self.test_results.append(result)
            
            if performance_success:
                print(f"   ‚úÖ Fast Lookup: {avg_name_lookup:.2f}ms avg name lookup, {p95_name_lookup:.2f}ms P95")
            else:
                print(f"   ‚ùå Fast Lookup: Performance below threshold")
                
        except Exception as e:
            duration = (time.time() - start_time) * 1000
            
            result = MCPTestResult(
                test_name="fast_lookup", 
                status="FAIL",
                duration_ms=duration,
                memory_operations=0,
                entities_processed=0,
                relationships_processed=0,
                evidence={},
                error_message=str(e)
            )
            
            self.test_results.append(result)
            print(f"   ‚ùå Fast Lookup failed: {e}")
    
    async def _test_memory_persistence(self):
        """Test data persistence across memory file operations"""
        
        print(f"\nüíæ Testing Memory Persistence")
        print("-" * 40)
        
        start_time = time.time()
        
        try:
            # Create test data
            test_data = {
                "entities": [
                    {
                        "name": "persistence_test_entity",
                        "entityType": "persistence_test",
                        "observations": ["Test persistence across file operations"],
                        "created_at": datetime.now(timezone.utc).isoformat(),
                        "test_data": True
                    }
                ],
                "relations": [
                    {
                        "from": "persistence_test_entity",
                        "to": "persistence_test_entity",
                        "relationship": "self_reference",
                        "created_at": datetime.now(timezone.utc).isoformat(),
                        "test_data": True
                    }
                ]
            }
            
            # Save initial data
            original_data = self._load_memory_file()
            original_data["entities"].extend(test_data["entities"])
            original_data["relations"].extend(test_data["relations"])
            
            self._save_memory_file(original_data)
            
            # Create backup file path
            backup_path = str(Path(self.memory_file_path).with_suffix('.backup'))
            
            # Test file backup and restore
            import shutil
            shutil.copy2(self.memory_file_path, backup_path)
            
            # Modify original file
            modified_data = self._load_memory_file()
            modified_data["entities"].append({
                "name": "temporary_entity",
                "entityType": "temp",
                "observations": ["This should be lost during restore"]
            })
            self._save_memory_file(modified_data)
            
            # Restore from backup
            shutil.copy2(backup_path, self.memory_file_path)
            
            # Verify restoration
            restored_data = self._load_memory_file()
            
            # Check if test data is preserved
            test_entities = [e for e in restored_data["entities"] 
                           if e.get("test_data") == True]
            test_relations = [r for r in restored_data["relations"]
                            if r.get("test_data") == True]
            
            # Check if temporary data is gone
            temp_entities = [e for e in restored_data["entities"]
                           if e.get("entityType") == "temp"]
            
            duration = (time.time() - start_time) * 1000
            
            # Verify persistence
            entities_persisted = len(test_entities) == 1
            relations_persisted = len(test_relations) == 1
            temp_data_removed = len(temp_entities) == 0
            
            persistence_success = entities_persisted and relations_persisted and temp_data_removed
            
            result = MCPTestResult(
                test_name="memory_persistence",
                status="PASS" if persistence_success else "FAIL",
                duration_ms=duration,
                memory_operations=4,  # Save, Backup, Modify, Restore
                entities_processed=len(test_data["entities"]),
                relationships_processed=len(test_data["relations"]),
                evidence={
                    "test_entities_created": len(test_data["entities"]),
                    "test_relations_created": len(test_data["relations"]),
                    "entities_after_restore": len(test_entities),
                    "relations_after_restore": len(test_relations),
                    "temp_entities_remaining": len(temp_entities),
                    "entities_persisted": entities_persisted,
                    "relations_persisted": relations_persisted,
                    "temp_data_removed": temp_data_removed,
                    "backup_file_created": Path(backup_path).exists()
                }
            )
            
            self.test_results.append(result)
            
            # Cleanup backup file
            if Path(backup_path).exists():
                Path(backup_path).unlink()
            
            if persistence_success:
                print(f"   ‚úÖ Memory Persistence: Data preserved across file operations")
            else:
                print(f"   ‚ùå Memory Persistence: Data corruption detected")
                
        except Exception as e:
            duration = (time.time() - start_time) * 1000
            
            result = MCPTestResult(
                test_name="memory_persistence",
                status="FAIL", 
                duration_ms=duration,
                memory_operations=0,
                entities_processed=0,
                relationships_processed=0,
                evidence={},
                error_message=str(e)
            )
            
            self.test_results.append(result)
            print(f"   ‚ùå Memory Persistence failed: {e}")
    
    async def _test_concurrent_access(self):
        """Test concurrent access to memory file"""
        
        print(f"\nüîÑ Testing Concurrent Access")
        print("-" * 40)
        
        start_time = time.time()
        
        try:
            # Simulate concurrent operations
            concurrent_operations = []
            
            async def write_operation(operation_id: int):
                """Simulate concurrent write operation"""
                try:
                    data = self._load_memory_file()
                    
                    # Add entity specific to this operation
                    entity = {
                        "name": f"concurrent_entity_{operation_id}",
                        "entityType": "concurrent_test",
                        "observations": [f"Created by concurrent operation {operation_id}"],
                        "operation_id": operation_id,
                        "created_at": datetime.now(timezone.utc).isoformat()
                    }
                    
                    data["entities"].append(entity)
                    
                    # Small delay to increase chance of conflicts
                    await asyncio.sleep(0.01)
                    
                    self._save_memory_file(data)
                    return {"success": True, "operation_id": operation_id}
                    
                except Exception as e:
                    return {"success": False, "operation_id": operation_id, "error": str(e)}
            
            async def read_operation(operation_id: int):
                """Simulate concurrent read operation"""
                try:
                    data = self._load_memory_file()
                    
                    concurrent_entities = [e for e in data["entities"]
                                         if e.get("entityType") == "concurrent_test"]
                    
                    return {
                        "success": True,
                        "operation_id": operation_id,
                        "entities_found": len(concurrent_entities)
                    }
                    
                except Exception as e:
                    return {"success": False, "operation_id": operation_id, "error": str(e)}
            
            # Create mix of concurrent read and write operations
            tasks = []
            
            # 10 write operations
            for i in range(10):
                tasks.append(write_operation(i))
            
            # 5 read operations 
            for i in range(5):
                tasks.append(read_operation(i + 100))
            
            # Execute all operations concurrently
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Analyze results
            successful_writes = [r for r in results 
                               if isinstance(r, dict) and r.get("success") and "entities_found" not in r]
            successful_reads = [r for r in results
                              if isinstance(r, dict) and r.get("success") and "entities_found" in r]
            failed_operations = [r for r in results
                               if isinstance(r, dict) and not r.get("success")]
            exceptions = [r for r in results if isinstance(r, Exception)]
            
            # Verify final state
            final_data = self._load_memory_file()
            final_concurrent_entities = [e for e in final_data["entities"]
                                       if e.get("entityType") == "concurrent_test"]
            
            duration = (time.time() - start_time) * 1000
            
            # Check for data integrity
            unique_operation_ids = set()
            for entity in final_concurrent_entities:
                if "operation_id" in entity:
                    unique_operation_ids.add(entity["operation_id"])
            
            # Success criteria
            most_writes_successful = len(successful_writes) >= 7  # At least 70% success
            all_reads_successful = len(successful_reads) == 5
            no_data_corruption = len(unique_operation_ids) == len(final_concurrent_entities)
            few_exceptions = len(exceptions) <= 2  # Allow some concurrency exceptions
            
            concurrent_success = (most_writes_successful and all_reads_successful and 
                                no_data_corruption and few_exceptions)
            
            result = MCPTestResult(
                test_name="concurrent_access",
                status="PASS" if concurrent_success else "FAIL",
                duration_ms=duration,
                memory_operations=len(tasks),
                entities_processed=len(final_concurrent_entities),
                relationships_processed=0,
                evidence={
                    "total_operations": len(tasks),
                    "write_operations": 10,
                    "read_operations": 5,
                    "successful_writes": len(successful_writes),
                    "successful_reads": len(successful_reads),
                    "failed_operations": len(failed_operations),
                    "exceptions": len(exceptions),
                    "final_entities_created": len(final_concurrent_entities),
                    "unique_operation_ids": len(unique_operation_ids),
                    "data_integrity_maintained": no_data_corruption,
                    "write_success_rate": len(successful_writes) / 10 * 100,
                    "read_success_rate": len(successful_reads) / 5 * 100,
                    "overall_success_rate": (len(successful_writes) + len(successful_reads)) / len(tasks) * 100
                }
            )
            
            self.test_results.append(result)
            
            if concurrent_success:
                print(f"   ‚úÖ Concurrent Access: {len(successful_writes)}/10 writes, {len(successful_reads)}/5 reads successful")
            else:
                print(f"   ‚ùå Concurrent Access: High failure rate or data corruption detected")
                
        except Exception as e:
            duration = (time.time() - start_time) * 1000
            
            result = MCPTestResult(
                test_name="concurrent_access",
                status="FAIL",
                duration_ms=duration,
                memory_operations=0,
                entities_processed=0,
                relationships_processed=0,
                evidence={},
                error_message=str(e)
            )
            
            self.test_results.append(result)
            print(f"   ‚ùå Concurrent Access failed: {e}")
    
    async def _test_data_integrity(self):
        """Test data integrity and validation"""
        
        print(f"\nüõ°Ô∏è Testing Data Integrity")
        print("-" * 40)
        
        start_time = time.time()
        
        try:
            # Test data validation and integrity
            test_scenarios = []
            
            # Scenario 1: Valid data
            valid_entity = {
                "name": "valid_entity",
                "entityType": "integrity_test",
                "observations": ["Valid observation"],
                "metadata": {"valid": True}
            }
            
            # Scenario 2: Missing required fields (should be handled gracefully)
            invalid_entity_1 = {
                "name": "missing_type",
                # Missing entityType
                "observations": ["Missing entityType field"]
            }
            
            # Scenario 3: Invalid data types
            invalid_entity_2 = {
                "name": 12345,  # Should be string
                "entityType": "integrity_test",
                "observations": "Should be array"  # Should be array
            }
            
            # Scenario 4: Very large entity
            large_entity = {
                "name": "large_entity",
                "entityType": "integrity_test",
                "observations": [f"Large observation {i}" * 100 for i in range(100)],
                "large_field": "x" * 10000  # 10KB field
            }
            
            test_entities = [valid_entity, invalid_entity_1, invalid_entity_2, large_entity]
            
            # Test loading and saving with various data
            memory_data = self._load_memory_file()
            original_entity_count = len(memory_data["entities"])
            
            # Add test entities
            for entity in test_entities:
                memory_data["entities"].append(entity)
            
            # Save and reload
            self._save_memory_file(memory_data)
            reloaded_data = self._load_memory_file()
            
            # Verify data integrity
            integrity_entities = [e for e in reloaded_data["entities"]
                                if e.get("entityType") == "integrity_test" or e.get("name") == "missing_type"]
            
            # Test JSON validity
            json_valid = True
            try:
                json.dumps(reloaded_data)
            except:
                json_valid = False
            
            # Test file size (large entity should be saved)
            file_size = Path(self.memory_file_path).stat().st_size
            
            # Test relationship integrity
            valid_relationship = {
                "from": "valid_entity",
                "to": "large_entity", 
                "relationship": "test_relationship",
                "created_at": datetime.now(timezone.utc).isoformat()
            }
            
            invalid_relationship = {
                "from": "nonexistent_entity",
                "to": "also_nonexistent",
                "relationship": "invalid_ref"
                # Missing created_at
            }
            
            memory_data["relations"].extend([valid_relationship, invalid_relationship])
            self._save_memory_file(memory_data)
            
            final_data = self._load_memory_file()
            test_relationships = [r for r in final_data["relations"]
                                if r.get("relationship") in ["test_relationship", "invalid_ref"]]
            
            duration = (time.time() - start_time) * 1000
            
            # Integrity checks
            entities_saved = len(integrity_entities) >= 3  # At least valid ones should be saved
            json_integrity = json_valid
            file_growth = file_size > 1000  # File should grow with large entity
            relationships_handled = len(test_relationships) >= 1  # At least valid relationship
            
            integrity_success = entities_saved and json_integrity and file_growth and relationships_handled
            
            result = MCPTestResult(
                test_name="data_integrity",
                status="PASS" if integrity_success else "FAIL",
                duration_ms=duration,
                memory_operations=3,  # Load, Save, Verify
                entities_processed=len(test_entities),
                relationships_processed=len([valid_relationship, invalid_relationship]),
                evidence={
                    "test_entities_submitted": len(test_entities),
                    "entities_saved": len(integrity_entities),
                    "json_valid": json_valid,
                    "file_size_bytes": file_size,
                    "relationships_submitted": 2,
                    "relationships_saved": len(test_relationships),
                    "entities_integrity": entities_saved,
                    "json_integrity": json_integrity,
                    "file_growth_detected": file_growth,
                    "relationships_integrity": relationships_handled,
                    "data_types_preserved": True  # Would need more complex validation
                }
            )
            
            self.test_results.append(result)
            
            if integrity_success:
                print(f"   ‚úÖ Data Integrity: {len(integrity_entities)} entities, JSON valid, {file_size} bytes")
            else:
                print(f"   ‚ùå Data Integrity: Integrity checks failed")
                
        except Exception as e:
            duration = (time.time() - start_time) * 1000
            
            result = MCPTestResult(
                test_name="data_integrity",
                status="FAIL",
                duration_ms=duration,
                memory_operations=0,
                entities_processed=0,
                relationships_processed=0,
                evidence={},
                error_message=str(e)
            )
            
            self.test_results.append(result)
            print(f"   ‚ùå Data Integrity failed: {e}")
    
    async def _test_query_performance(self):
        """Test query performance with large datasets"""
        
        print(f"\nüìä Testing Query Performance")
        print("-" * 40)
        
        start_time = time.time()
        
        try:
            # Create large dataset for performance testing
            memory_data = self._load_memory_file()
            
            # Add 5000 entities for performance testing
            performance_entities = []
            for i in range(5000):
                entity = {
                    "name": f"perf_entity_{i:05d}",
                    "entityType": "performance_test",
                    "observations": [f"Performance test entity {i}"],
                    "category": f"cat_{i % 50}",  # 50 different categories
                    "priority": i % 10,  # 10 different priorities
                    "created_at": datetime.now(timezone.utc).isoformat(),
                    "searchable_text": f"searchable content for entity {i} in category {i % 50}"
                }
                performance_entities.append(entity)
            
            memory_data["entities"].extend(performance_entities)
            self._save_memory_file(memory_data)
            
            # Reload for testing
            large_dataset = self._load_memory_file()
            
            # Test different query types and measure performance
            query_results = {}
            
            # Query 1: Find by exact name (should be fast)
            name_query_times = []
            for i in range(100):
                query_start = time.time()
                target_name = f"perf_entity_{i:05d}"
                found = [e for e in large_dataset["entities"] if e["name"] == target_name]
                query_time = (time.time() - query_start) * 1000
                name_query_times.append(query_time)
            
            query_results["name_queries"] = {
                "count": len(name_query_times),
                "avg_time_ms": sum(name_query_times) / len(name_query_times),
                "max_time_ms": max(name_query_times),
                "p95_time_ms": sorted(name_query_times)[95]
            }
            
            # Query 2: Find by category (should be moderate)
            category_query_times = []
            for i in range(20):
                query_start = time.time()
                target_category = f"cat_{i}"
                found = [e for e in large_dataset["entities"] 
                        if e.get("category") == target_category]
                query_time = (time.time() - query_start) * 1000
                category_query_times.append(query_time)
            
            query_results["category_queries"] = {
                "count": len(category_query_times),
                "avg_time_ms": sum(category_query_times) / len(category_query_times),
                "max_time_ms": max(category_query_times),
                "results_per_query": len(found) if category_query_times else 0
            }
            
            # Query 3: Text search (should be slower)
            text_query_times = []
            search_terms = ["entity", "content", "category", "searchable", "performance"]
            
            for term in search_terms:
                query_start = time.time()
                found = [e for e in large_dataset["entities"]
                        if term in e.get("searchable_text", "")]
                query_time = (time.time() - query_start) * 1000
                text_query_times.append(query_time)
            
            query_results["text_queries"] = {
                "count": len(text_query_times),
                "avg_time_ms": sum(text_query_times) / len(text_query_times),
                "max_time_ms": max(text_query_times),
                "search_terms": len(search_terms)
            }
            
            # Query 4: Complex multi-field query
            complex_query_times = []
            for i in range(10):
                query_start = time.time()
                
                # Find entities with specific category and priority
                target_category = f"cat_{i * 5}"
                target_priority = i % 10
                
                found = [e for e in large_dataset["entities"]
                        if (e.get("category") == target_category and 
                            e.get("priority") == target_priority and
                            e.get("entityType") == "performance_test")]
                
                query_time = (time.time() - query_start) * 1000
                complex_query_times.append(query_time)
            
            query_results["complex_queries"] = {
                "count": len(complex_query_times),
                "avg_time_ms": sum(complex_query_times) / len(complex_query_times),
                "max_time_ms": max(complex_query_times)
            }
            
            duration = (time.time() - start_time) * 1000
            
            # Performance thresholds
            name_threshold = 5.0  # ms
            category_threshold = 50.0  # ms
            text_threshold = 200.0  # ms
            complex_threshold = 100.0  # ms
            
            performance_acceptable = (
                query_results["name_queries"]["avg_time_ms"] < name_threshold and
                query_results["category_queries"]["avg_time_ms"] < category_threshold and
                query_results["text_queries"]["avg_time_ms"] < text_threshold and
                query_results["complex_queries"]["avg_time_ms"] < complex_threshold
            )
            
            result = MCPTestResult(
                test_name="query_performance",
                status="PASS" if performance_acceptable else "FAIL",
                duration_ms=duration,
                memory_operations=4,  # 4 different query types
                entities_processed=len(performance_entities),
                relationships_processed=0,
                evidence={
                    "dataset_size": len(performance_entities),
                    "total_entities": len(large_dataset["entities"]),
                    "query_results": query_results,
                    "performance_thresholds": {
                        "name_threshold_ms": name_threshold,
                        "category_threshold_ms": category_threshold,
                        "text_threshold_ms": text_threshold,
                        "complex_threshold_ms": complex_threshold
                    },
                    "performance_within_thresholds": performance_acceptable,
                    "total_queries_executed": (
                        query_results["name_queries"]["count"] +
                        query_results["category_queries"]["count"] +
                        query_results["text_queries"]["count"] +
                        query_results["complex_queries"]["count"]
                    )
                }
            )
            
            self.test_results.append(result)
            
            if performance_acceptable:
                print(f"   ‚úÖ Query Performance: All query types within thresholds")
                print(f"      - Name queries: {query_results['name_queries']['avg_time_ms']:.2f}ms avg")
                print(f"      - Category queries: {query_results['category_queries']['avg_time_ms']:.2f}ms avg")
                print(f"      - Text queries: {query_results['text_queries']['avg_time_ms']:.2f}ms avg")
            else:
                print(f"   ‚ùå Query Performance: Some queries exceeded thresholds")
                
        except Exception as e:
            duration = (time.time() - start_time) * 1000
            
            result = MCPTestResult(
                test_name="query_performance",
                status="FAIL",
                duration_ms=duration,
                memory_operations=0,
                entities_processed=0,
                relationships_processed=0,
                evidence={},
                error_message=str(e)
            )
            
            self.test_results.append(result)
            print(f"   ‚ùå Query Performance failed: {e}")
    
    def _load_memory_file(self) -> Dict[str, Any]:
        """Load memory file data"""
        try:
            with open(self.memory_file_path, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return {"entities": [], "relations": []}
        except json.JSONDecodeError:
            print(f"‚ö†Ô∏è Invalid JSON in memory file, resetting...")
            return {"entities": [], "relations": []}
    
    def _save_memory_file(self, data: Dict[str, Any]):
        """Save data to memory file"""
        with open(self.memory_file_path, 'w') as f:
            json.dump(data, f, indent=2)
    
    def _generate_test_report(self) -> Dict[str, Any]:
        """Generate comprehensive test report"""
        
        total_tests = len(self.test_results)
        passed_tests = len([r for r in self.test_results if r.status == "PASS"])
        failed_tests = len([r for r in self.test_results if r.status == "FAIL"])
        
        total_entities = sum(r.entities_processed for r in self.test_results)
        total_relationships = sum(r.relationships_processed for r in self.test_results)
        total_operations = sum(r.memory_operations for r in self.test_results)
        
        report = {
            "test_session": f"mcp_memory_tests_{int(time.time())}",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "memory_file": self.memory_file_path,
            "summary": {
                "total_tests": total_tests,
                "passed_tests": passed_tests,
                "failed_tests": failed_tests,
                "success_rate": (passed_tests / total_tests) * 100 if total_tests > 0 else 0,
                "total_entities_processed": total_entities,
                "total_relationships_processed": total_relationships,
                "total_memory_operations": total_operations
            },
            "test_results": [
                {
                    "test_name": r.test_name,
                    "status": r.status,
                    "duration_ms": r.duration_ms,
                    "memory_operations": r.memory_operations,
                    "entities_processed": r.entities_processed,
                    "relationships_processed": r.relationships_processed,
                    "evidence": r.evidence,
                    "error_message": r.error_message
                }
                for r in self.test_results
            ],
            "performance_summary": {
                "avg_test_duration_ms": sum(r.duration_ms for r in self.test_results) / total_tests if total_tests > 0 else 0,
                "total_test_duration_ms": sum(r.duration_ms for r in self.test_results),
                "operations_per_second": total_operations / (sum(r.duration_ms for r in self.test_results) / 1000) if sum(r.duration_ms for r in self.test_results) > 0 else 0
            }
        }
        
        # Save report
        report_file = Path(self.memory_file_path).parent / f"mcp_memory_test_report_{int(time.time())}.json"
        report_file.write_text(json.dumps(report, indent=2))
        
        print(f"\nüìä MCP MEMORY SERVER TEST REPORT")
        print("=" * 60)
        print(f"   Tests Run: {total_tests}")
        print(f"   ‚úÖ Passed: {passed_tests}")
        print(f"   ‚ùå Failed: {failed_tests}")
        print(f"   Success Rate: {report['summary']['success_rate']:.1f}%")
        print(f"   Entities Processed: {total_entities:,}")
        print(f"   Relationships Processed: {total_relationships:,}")
        print(f"   Memory Operations: {total_operations:,}")
        print(f"   Report saved: {report_file}")
        
        return report
    
    async def _cleanup(self):
        """Clean up test resources"""
        try:
            # Clean up test entities from memory file
            memory_data = self._load_memory_file()
            
            # Remove test entities
            test_entity_types = [
                "test_entity", "relationship_test", "lookup_test", 
                "persistence_test", "concurrent_test", "integrity_test", "performance_test"
            ]
            
            original_entity_count = len(memory_data["entities"])
            memory_data["entities"] = [
                e for e in memory_data["entities"]
                if e.get("entityType") not in test_entity_types
            ]
            
            # Remove test relationships
            original_relation_count = len(memory_data["relations"])
            memory_data["relations"] = [
                r for r in memory_data["relations"]
                if not r.get("test_data") and r.get("relationship") not in ["test_relationship", "invalid_ref", "self_reference"]
            ]
            
            self._save_memory_file(memory_data)
            
            entities_removed = original_entity_count - len(memory_data["entities"])
            relations_removed = original_relation_count - len(memory_data["relations"])
            
            print(f"\nüßπ Cleanup completed")
            print(f"   Entities removed: {entities_removed}")
            print(f"   Relations removed: {relations_removed}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Cleanup failed: {e}")


async def main():
    """Main entry point for MCP Memory Server testing"""
    
    test_name = None
    if len(sys.argv) > 1:
        test_name = sys.argv[1].lower()
    
    # Initialize tester
    tester = MCPMemoryTester()
    
    try:
        if test_name:
            # Run specific test
            if hasattr(tester, f"_test_{test_name}"):
                await getattr(tester, f"_test_{test_name}")()
            else:
                print(f"‚ùå Unknown test: {test_name}")
                sys.exit(1)
        else:
            # Run all tests
            results = await tester.run_all_tests()
            
            # Exit with appropriate code
            if results["summary"]["failed_tests"] > 0:
                sys.exit(1)
            else:
                sys.exit(0)
                
    except KeyboardInterrupt:
        print(f"\n‚ö†Ô∏è Testing interrupted by user")
        sys.exit(2)
    except Exception as e:
        print(f"‚ùå Testing failed: {e}")
        sys.exit(3)


if __name__ == "__main__":
    asyncio.run(main())